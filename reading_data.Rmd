---
title: "Reading data"
author: "Lucia Wang"
date: "2023-10-10"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(httr)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

First import NSDUH data from html.
```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

nsduh_html = read_html(url)
```

Now pull out the elements that are relevant.
```{r}
nsduh_html |>
  html_table()
```
This imported the table, but it imported all the tables. So we need to pick just the ones we want.
```{r}
marij_use_df = 
  nsduh_html |>
  html_table() |>
  first() |>
  slice(-1)
```

Star wars data
```{r}
swm_html = 
  read_html("https://www.imdb.com/list/ls070150896/")
```

use selector gadget to get the html elements
```{r}
swm_title_vec =
  swm_html |>
  html_elements(".lister-item-header a") |>
  html_text()

swm_grossrev_vec = 
  swm_html |>
  html_elements(".text-small:nth-child(7) span:nth-child(5)") |>
  html_text()

swm_df = 
  tibble(
    title = swm_title_vec,
    gross_rev = swm_grossrev_vec
  )
```

Using API...(use the link from API endpoint)
```{r}
nyc_water_df = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") |> 
  content("parsed")
```
  
BRFSS - request the limit of rows, parse data, etc.
```{r}
brfss_smart2010 = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv",
      query = list("$limit" = 5000)) |> 
  content("parsed")
```

Pokemon?
```{r}
poke = 
  GET("http://pokeapi.co/api/v2/pokemon/1") |>
  content()

poke$name
```


